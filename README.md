# Pranav-s_Portfolio

# Data engineering And Analytics Portfoilo

# [Data_Engineering and Automation - Project 1](https://github.com/Pranavprasanthan/data-engg.git)
# Data engineering and automation on imported data from an API using Python V3.7, Docker and Pandas as an algorithm.

Project structure:
1  Creating a docker-compose.yml file to define the containers and services.
2 Creating a requirements.txt file to specify the project dependencies.
3  Implement the data ingestion pipeline:
4  Creating a Python script to fetch data from the API.
5  Processing the fetched data and extract the required fields (country, name, surname, gender).
6  Storing the extracted data in a staging table in the PostgreSQL database.
7  Implementing the data transformation and loading (ETL) process:
8  Creating a Python script to transform the data from the staging table.
9  Creating a production table in the PostgreSQL database.
10  Loading the transformed data into the production table.
11  Verifying the data in the database:
12  Connect to the PostgreSQL database.
13  Query the production table to ensure the data is available.
14  Create unit tests to verify the functionality of the data ingestion and ETL processes.
15  Dockerizing the application:
16  Creating a Dockerfile for the Python application.
17  Using Docker Compose to set up the containers and services.

# [Data_profiling - Project 2](https://github.com/Pranavprasanthan/Data_profiling.git)
# Data profiling and automation on imported data from the UK government website of different attributes concerning petroleum sectors is done using Python V3.7 and Pandas as an algorithm. 
The data manupulation processs involves  the following: the data manupulation processs involves  the following:  
1. A script that can check for new data, and if a new dataset is detected. Download the new Excel file.
2. Cleaning the data to remove any unnecessary information and to ensure that the data is in a 
consistent and well-structured format.
  a. Min, max, median, and mean;
  b. Number of missing values.
  c. The absence of columns from earlier reports or Null data.
  d. Data visualisation using Matlab
  e. Ensuring that any dates and timestamps are converted into a standard dateformat of 
   yyyy-MM-dd and yyyy-MM-dd HH:mm:ss for timestamps
  f. Retain information about when the data was processed and the original filename
4. Save the resulting DataFrame to a CSV file in a format that can be easily ingested into a data 
lake.


# [Data visualisation - Project 3](https://github.com/Pranavprasanthan/Market_share.git)
Job market share by various MNC's in india

This project uses an online database to analyse, and visualise data regarding which key firms are thriving in India's data analytics industry and the market share of the Indian IT sector controlled by these organisations that was imported from "Kaggle."
